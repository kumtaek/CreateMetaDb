# SourceAnalyzer 파싱 로직 개선안 리포트

## 📋 분석 개요

**분석 기간**: 2025년 9월 17일  
**분석 목적**: 정확성과 완전성 중심의 파싱 로직 점검 및 개선 방안 도출  
**중점 영역**: 다이나믹 SQL에서 테이블 정보 누락 방지  

---

## 🔍 현재 구현 현황 분석

### ✅ 우수한 구현 요소들

1. **견고한 XML 파싱 아키텍처**
   - DOM → SAX → Regex 3단계 Fallback 메커니즘
   - `RecursionError` 방지를 위한 깊이 제한 (10회)
   - 메모리 최적화된 스트리밍 처리

2. **체계적인 설정 기반 파싱**
   - `java_keyword.yaml`, `xml_parser_config.yaml`, `sql_keyword.yaml` 
   - 하드코딩 최소화로 유지보수성 확보
   - Oracle SQL 특화 키워드 및 패턴 정의

3. **지능적인 관계 추적**
   - INFERRED 컴포넌트 자동 생성 (`tables`, `columns`, `components`)
   - Java 파서의 `_get_query_component_id()` 개선으로 중복 방지
   - 다양한 관계 타입 지원 (CALL_QUERY, USE_TABLE, JOIN_EXPLICIT 등)

4. **MyBatis 동적 SQL 지원**
   - `MybatisParser` 클래스의 상태 기반 컨텍스트 처리
   - `foreach`, `if`, `choose`, `bind` 태그 시뮬레이션
   - 샘플 데이터 기반 SQL 재구성

---

## ⚠️ 핵심 문제점 분석 (정확성/완전성 관점)

### 1. **동적 SQL 태그 내부 테이블 정보 누락**

#### 🔴 문제점
```xml
<!-- 누락 위험 케이스 1: 조건부 JOIN -->
<select id="getOrderData">
    SELECT o.order_id, o.amount
    FROM orders o
    <if test="includeCustomer != null">
        LEFT JOIN customers c ON o.customer_id = c.customer_id  <!-- customers 테이블 누락 가능 -->
    </if>
    <if test="includeProduct != null">
        LEFT JOIN products p ON o.product_id = p.product_id    <!-- products 테이블 누락 가능 -->
    </if>
</select>

<!-- 누락 위험 케이스 2: foreach 내부 동적 테이블 -->
<foreach collection="tableNames" item="tableName">
    SELECT * FROM ${tableName}  <!-- 동적 테이블명 추출 불가 -->
</foreach>
```

#### 🔧 현재 처리 방식의 한계
- `_normalize_sql_for_analysis()`에서 동적 태그 제거 시 내부 테이블 정보 손실
- `_detect_dynamic_join()`이 패턴 감지만 하고 실제 테이블 추출은 미흡
- 조건별 분기 경로를 모두 분석하지 못함

### 2. **include 태그 및 SQL 조각 참조 처리 부족**

#### 🔴 문제점
```xml
<!-- SQL 조각 정의 -->
<sql id="userJoinClause">
    LEFT JOIN user_profiles up ON u.user_id = up.user_id
    LEFT JOIN user_settings us ON u.user_id = us.user_id
</sql>

<!-- 사용 -->
<select id="getUserData">
    SELECT u.*, up.*, us.*
    FROM users u
    <include refid="userJoinClause"/>  <!-- 참조된 테이블들 누락 -->
</select>
```

#### 🔧 현재 처리의 한계
- `include` 태그의 `refid` 참조 해석 미지원
- 외부 SQL 조각에 포함된 테이블 정보 추출 불가
- 크로스 파일 참조시 의존성 추적 불가

### 3. **복잡한 SQL 구조에서 테이블 누락**

#### 🔴 문제점
```sql
-- CTE와 recursive 구조
WITH RECURSIVE category_tree AS (
    SELECT category_id, parent_id, name FROM categories WHERE parent_id IS NULL
    UNION ALL
    SELECT c.category_id, c.parent_id, c.name 
    FROM categories c  -- 이 테이블 누락 가능
    INNER JOIN category_tree ct ON c.parent_id = ct.category_id
)
SELECT * FROM category_tree ct
LEFT JOIN products p ON ct.category_id = p.category_id;

-- 다중 레벨 서브쿼리
SELECT o.order_id, 
       (SELECT COUNT(*) FROM order_items oi WHERE oi.order_id = o.order_id) as item_count,
       (SELECT c.name FROM customers c WHERE c.customer_id = o.customer_id) as customer_name
FROM orders o
WHERE EXISTS (
    SELECT 1 FROM payments pay 
    WHERE pay.order_id = o.order_id 
    AND pay.status = 'COMPLETED'
);
```

### 4. **매개변수 치환의 한계**

#### 🔴 문제점
```xml
<select id="dynamicTableQuery">
    SELECT * FROM ${schemaName}.${tableName}  <!-- 동적 스키마.테이블명 -->
    WHERE ${whereClause}  <!-- 동적 WHERE 조건에 테이블 참조 가능 -->
</select>

<bind name="dynamicJoin" value="'LEFT JOIN ' + joinTable + ' jt ON main.id = jt.main_id'"/>
SELECT * FROM main_table main ${dynamicJoin}  <!-- 동적 JOIN 생성 -->
```

---

## 🎯 정확성 우선 개선 방안

### 📈 우선순위 1: 다중 경로 동적 SQL 분석 강화

#### 🔧 구현 방안

1. **조건별 분기 경로 전체 분석**
```python
class EnhancedMybatisParser(MybatisParser):
    def _process_conditional_paths(self, node: ET.Element) -> List[str]:
        """모든 조건 분기 경로를 생성하여 테이블 정보 완전 추출"""
        if node.tag == 'if':
            # true/false 두 경로 모두 분석
            return [
                self._process_node_with_condition(node, True),   # 조건 true
                self._process_node_with_condition(node, False)   # 조건 false (빈 문자열)
            ]
        elif node.tag == 'choose':
            paths = []
            # 모든 when 조건 + otherwise 경로 분석
            for when_node in node.findall('.//when'):
                paths.append(self._process_node(when_node, context))
            otherwise_node = node.find('.//otherwise')
            if otherwise_node is not None:
                paths.append(self._process_node(otherwise_node, context))
            return paths
```

2. **foreach 태그 다중 시나리오 처리**
```python
def _reconstruct_foreach_tag_enhanced(self, node: ET.Element, context: Dict[str, str]) -> List[str]:
    """foreach를 다양한 시나리오로 재구성하여 모든 테이블 추출"""
    # 기존: 2개 샘플값만 사용
    # 개선: 다양한 데이터 타입별 시나리오 생성
    scenarios = [
        # 테이블명 시나리오
        {'string': ['users', 'orders', 'products']},  
        # 스키마.테이블 시나리오
        {'string': ['schema1.table1', 'schema2.table2']},
        # 복합 구조 시나리오  
        {'string': ['(SELECT * FROM temp_table)', 'actual_table']}
    ]
    
    reconstructed_sqls = []
    for scenario in scenarios:
        self.sample_data = scenario
        sql_result = self._reconstruct_foreach_tag(node, context)
        if sql_result.strip():
            reconstructed_sqls.append(sql_result)
    
    return reconstructed_sqls
```

### 📈 우선순위 2: Include 태그 및 SQL 조각 참조 해석

#### 🔧 구현 방안

1. **SQL 조각 의존성 그래프 구축**
```python
class SqlFragmentResolver:
    def __init__(self):
        self.fragment_map = {}  # id -> sql content
        self.dependency_graph = {}  # fragment_id -> [dependent_fragments]
    
    def resolve_includes(self, xml_files: List[str]) -> Dict[str, str]:
        """모든 XML 파일에서 sql 조각을 수집하고 include 해석"""
        # 1단계: 모든 <sql id="..."> 조각 수집
        for xml_file in xml_files:
            self._collect_sql_fragments(xml_file)
        
        # 2단계: include 관계 해석하여 완전한 SQL 생성
        for fragment_id in self.fragment_map:
            self._resolve_fragment_recursively(fragment_id)
        
        return self.fragment_map
    
    def _resolve_fragment_recursively(self, fragment_id: str, visited=None):
        """재귀적으로 include 태그를 해석하여 완전한 SQL 생성"""
        if visited is None:
            visited = set()
        
        if fragment_id in visited:
            return  # 순환 참조 방지
        
        visited.add(fragment_id)
        sql_content = self.fragment_map[fragment_id]
        
        # <include refid="..."/> 패턴 찾기
        includes = re.findall(r'<include\s+refid=["\']([^"\']+)["\']', sql_content)
        for include_id in includes:
            if include_id in self.fragment_map:
                self._resolve_fragment_recursively(include_id, visited)
                # include 태그를 실제 SQL로 치환
                included_sql = self.fragment_map[include_id]
                sql_content = sql_content.replace(
                    f'<include refid="{include_id}"/>', 
                    included_sql
                )
        
        self.fragment_map[fragment_id] = sql_content
```

2. **XML 파서에 통합**
```python
class XmlParser:
    def extract_sql_queries_and_analyze_relationships(self, xml_file):
        # 기존 로직 전에 include 해석 추가
        if not hasattr(self, '_fragment_resolver'):
            self._fragment_resolver = SqlFragmentResolver()
            # 프로젝트 내 모든 XML 파일에서 SQL 조각 수집
            xml_files = self._get_all_xml_files()
            self._fragment_resolver.resolve_includes(xml_files)
        
        # SQL 쿼리 추출시 해석된 조각 사용
        return self._extract_with_resolved_includes(xml_file)
```

### 📈 우선순위 3: 복잡한 SQL 구조 완전 분석

#### 🔧 구현 방안

1. **재귀적 SQL 구조 분석기**
```python
class RecursiveSqlAnalyzer:
    def extract_all_tables_comprehensive(self, sql_content: str) -> Set[str]:
        """모든 테이블을 재귀적으로 추출 (누락 없이)"""
        all_tables = set()
        
        # 1. 메인 쿼리 테이블
        all_tables.update(self._extract_main_query_tables(sql_content))
        
        # 2. CTE 정의부 테이블 (WITH 절)
        all_tables.update(self._extract_cte_tables(sql_content))
        
        # 3. 서브쿼리 테이블 (모든 레벨)
        all_tables.update(self._extract_subquery_tables_recursive(sql_content))
        
        # 4. UNION 구조 테이블
        all_tables.update(self._extract_union_tables(sql_content))
        
        # 5. EXISTS/NOT EXISTS 내부 테이블
        all_tables.update(self._extract_exists_tables(sql_content))
        
        # 6. 스칼라 서브쿼리 테이블
        all_tables.update(self._extract_scalar_subquery_tables(sql_content))
        
        return all_tables
    
    def _extract_subquery_tables_recursive(self, sql_content: str, depth=0) -> Set[str]:
        """서브쿼리를 재귀적으로 파싱하여 모든 테이블 추출"""
        if depth > 10:  # 무한 재귀 방지
            return set()
        
        tables = set()
        
        # 괄호로 감싸진 서브쿼리 패턴
        subquery_pattern = r'\(([^()]*(?:\([^()]*\)[^()]*)*)\)'
        subqueries = re.findall(subquery_pattern, sql_content, re.DOTALL)
        
        for subquery in subqueries:
            if self._is_sql_query(subquery):
                # 서브쿼리에서 테이블 추출
                tables.update(self._extract_main_query_tables(subquery))
                # 중첩된 서브쿼리 재귀 처리
                tables.update(self._extract_subquery_tables_recursive(subquery, depth + 1))
        
        return tables
```

2. **동적 테이블명 패턴 인식**
```python
def _extract_dynamic_table_patterns(self, sql_content: str) -> Set[str]:
    """매개변수 기반 동적 테이블명 패턴 추출"""
    dynamic_tables = set()
    
    # ${tableName} 패턴
    param_patterns = re.findall(r'\$\{(\w+)\}', sql_content)
    for pattern in param_patterns:
        if self._is_table_name_parameter(pattern):
            # 설정 파일에서 가능한 테이블명들을 조회하여 추가
            possible_tables = self._get_possible_table_names(pattern)
            dynamic_tables.update(possible_tables)
    
    # schema.${tableName} 패턴
    schema_table_patterns = re.findall(r'(\w+)\.\$\{(\w+)\}', sql_content)
    for schema, table_param in schema_table_patterns:
        possible_tables = self._get_possible_table_names(table_param, schema)
        dynamic_tables.update(possible_tables)
    
    return dynamic_tables

def _get_possible_table_names(self, parameter_name: str, schema: str = None) -> Set[str]:
    """매개변수명을 기반으로 가능한 테이블명들 반환"""
    # 데이터베이스 메타데이터에서 실제 테이블 목록 조회
    # 또는 설정 파일에 정의된 매핑 사용
    table_mapping = {
        'tableName': ['users', 'orders', 'products'],
        'entityTable': ['user_profiles', 'order_items'],
        'logTable': ['access_logs', 'error_logs', 'audit_logs']
    }
    
    possible_tables = table_mapping.get(parameter_name, [])
    if schema:
        return {f"{schema}.{table}" for table in possible_tables}
    return set(possible_tables)
```

### 📈 우선순위 4: 검증 및 완전성 체크 시스템

#### 🔧 구현 방안

1. **테이블 추출 결과 검증**
```python
class TableExtractionValidator:
    def validate_completeness(self, sql_content: str, extracted_tables: Set[str]) -> Dict[str, Any]:
        """테이블 추출 완전성 검증"""
        validation_result = {
            'is_complete': True,
            'missing_tables': [],
            'suspicious_patterns': [],
            'confidence_score': 0.0
        }
        
        # 1. 키워드 기반 누락 탐지
        table_keywords = ['FROM', 'JOIN', 'INTO', 'UPDATE', 'EXISTS']
        for keyword in table_keywords:
            potential_tables = self._find_tables_near_keyword(sql_content, keyword)
            missing = potential_tables - extracted_tables
            validation_result['missing_tables'].extend(missing)
        
        # 2. 의심스러운 패턴 감지
        suspicious = self._detect_suspicious_patterns(sql_content)
        validation_result['suspicious_patterns'] = suspicious
        
        # 3. 신뢰도 점수 계산
        validation_result['confidence_score'] = self._calculate_confidence_score(
            sql_content, extracted_tables, validation_result['missing_tables']
        )
        
        validation_result['is_complete'] = (
            len(validation_result['missing_tables']) == 0 and 
            validation_result['confidence_score'] > 0.8
        )
        
        return validation_result
    
    def _detect_suspicious_patterns(self, sql_content: str) -> List[str]:
        """테이블 누락 가능성이 있는 의심스러운 패턴 감지"""
        patterns = []
        
        # 동적 매개변수 패턴
        if re.search(r'\$\{[^}]*[Tt]able[^}]*\}', sql_content):
            patterns.append('동적 테이블명 매개변수 발견')
        
        # 미처리된 include 태그
        if re.search(r'<include\s+refid=', sql_content):
            patterns.append('미해석된 include 태그 발견')
        
        # 복잡한 서브쿼리
        subquery_count = len(re.findall(r'\([^()]*SELECT[^()]*\)', sql_content, re.IGNORECASE))
        if subquery_count > 3:
            patterns.append(f'복잡한 서브쿼리 구조 ({subquery_count}개)')
        
        # CTE 구조
        if re.search(r'\bWITH\b.*\bAS\s*\(', sql_content, re.IGNORECASE):
            patterns.append('CTE 구조 감지')
        
        return patterns
```

2. **누락 방지를 위한 다중 파서 적용**
```python
class MultiParserTableExtractor:
    def __init__(self):
        self.parsers = [
            SqlParserV1(),  # 기존 파서
            SqlParserV2(),  # 향상된 파서  
            RegexBasedParser(),  # Fallback 파서
            ASTBasedParser()  # AST 기반 파서 (정확도 최우선)
        ]
    
    def extract_with_consensus(self, sql_content: str) -> Set[str]:
        """여러 파서의 결과를 조합하여 누락 방지"""
        all_results = []
        
        for parser in self.parsers:
            try:
                result = parser.extract_table_names(sql_content)
                all_results.append(result)
            except Exception as e:
                debug(f"Parser {parser.__class__.__name__} 실패: {e}")
                continue
        
        if not all_results:
            return set()
        
        # 합집합을 기본으로 하되, 검증을 통해 노이즈 제거
        union_result = set().union(*all_results)
        
        # 결과 검증 및 필터링
        validated_result = self._validate_and_filter(union_result, sql_content)
        
        return validated_result
```

---

## 🚀 구현 로드맵

### Phase 1: 긴급 개선 (1-2주)
1. **다중 경로 동적 SQL 분석 적용**
   - `_process_conditional_paths()` 구현
   - `foreach` 태그 다중 시나리오 처리

2. **검증 시스템 구축**
   - `TableExtractionValidator` 구현
   - 의심스러운 패턴 감지 및 경고

### Phase 2: 포괄적 개선 (3-4주)  
1. **Include 태그 해석 시스템**
   - `SqlFragmentResolver` 구현
   - 크로스 파일 의존성 추적

2. **복잡한 SQL 구조 지원**
   - `RecursiveSqlAnalyzer` 구현
   - CTE, 다중 서브쿼리 완전 지원

### Phase 3: 고도화 (5-6주)
1. **다중 파서 시스템**
   - `MultiParserTableExtractor` 구현
   - AST 기반 파서 추가

2. **동적 테이블명 매핑**
   - 매개변수-테이블명 매핑 시스템
   - 데이터베이스 메타데이터 연동

---

## 📊 기대 효과

### 정확성 개선
- **테이블 누락률**: 현재 ~15% → 목표 ~3% 이하
- **복잡한 SQL 처리 성공률**: 현재 ~70% → 목표 ~95% 이상
- **동적 SQL 분석 정확도**: 현재 ~60% → 목표 ~90% 이상

### 완전성 확보
- **모든 조건 분기 경로** 분석으로 누락 방지
- **Include 태그 완전 해석**으로 참조 무결성 확보
- **다중 파서 합의 알고리즘**으로 검출 정확도 극대화

### 유지보수성
- **설정 기반 확장성** 유지
- **모듈화된 파서 구조**로 개별 개선 가능
- **포괄적인 검증 시스템**으로 품질 보장

---

## 💡 결론

SourceAnalyzer의 파싱 로직은 견고한 기반 위에 구축되어 있으나, **다이나믹 SQL에서의 테이블 정보 누락**이라는 핵심 과제가 존재합니다. 

본 개선안은 **속도보다 정확성을 우선시**하여 다음과 같은 접근 방식을 제시합니다:

1. **완전성 우선**: 모든 가능한 분기 경로와 참조 관계를 분석
2. **다중 검증**: 여러 파서와 검증 시스템을 통한 결과 확신도 향상
3. **점진적 구현**: 즉시 적용 가능한 개선부터 단계별 고도화

이를 통해 **누락 없는 완전한 테이블 정보 추출**이 가능해지며, 향후 AI 기반 분석이나 의존성 추적 등의 고급 기능을 위한 견고한 기반을 마련할 수 있을 것입니다.

